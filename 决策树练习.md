from sklearn import tree
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
wine=load_wine()#数据初始化
wine.target

import pandas as pd
pd.concat([pd.DataFrame(wine.data),pd.DataFrame(wine.target)],axis=1)
wine.target_names
Xtrain,Xtest,Ytrain,Ytest=train_test_split(wine.data,wine.target,test_size=0.3)#训练集/测试集
#建模
clf=tree.DecisionTreeClassifier(criterion="entropy"
                               ,random_state=30
                               ,splitter="random")
clf=clf.fit(Xtrain,Ytrain)
score=clf.score(Xtest,Ytest)
score
feature_name=["酒精","苹果酸","灰","灰碱性","M","总酚","类黄铜","非黄烷","青","颜色强度","色调","od280","脯氨酸"]

#画一颗决策树
import graphviz
dot_data=tree.export_graphviz(clf,
                              feature_names=feature_name,
                              class_names=["琴酒","雪莉","贝尔摩德"],
                              filled=True
                              ,rounded=True
                             )
graph=graphviz.Source(dot_data)
graph #展现效果
clf.feature_importances_
[*zip(feature_name,clf.feature_importances_)]

#参数设置
#建模
clf=tree.DecisionTreeClassifier(criterion="entropy"
                               ,random_state=36
                               ,splitter="random"
                               ,max_depth=3
                               ,min_samples_leaf=18
                               ,min_samples_split=10)
clf=clf.fit(Xtrain,Ytrain)
score=clf.score(Xtest,Ytest)
import graphviz
dot_data=tree.export_graphviz(clf,
                              feature_names=feature_name,
                              class_names=["琴酒","雪莉","贝尔摩德"],
                              filled=True
                              ,rounded=True
                             )
graph=graphviz.Source(dot_data)
graph

#看看有参数后测试分与训练分效果
clf=clf.fit(Xtrain,Ytrain)
score=clf.score(Xtest,Ytest)
score_train=clf.score(Xtrain,Ytrain)
score
score_train

#折线图绘制//方便寻找最佳参数值//超参数的学习曲线
import matplotlib.pyplot as plt
test=[]

for i in range(10):
    clf=tree.DecisionTreeClassifier(max_depth=i+1
                                    ,criterion="entropy"
                                    ,splitter="random"
                                    ,random_state=36
                                    ,min_samples_leaf=18
                                    ,min_samples_split=10
                                    ,max_features=10
                                   )
    clf=clf.fit(Xtrain,Ytrain)
    score=clf.score(Xtest,Ytest)
    test.append(score)

plt.plot(range(1,11),test,color='r',label="max_depth")
plt.legend()
plt.show()

clf.apply(Xtest)
clf.predict(Xtest)
from sklearn.metrics import accuracy_score
Ypred=clf.predict(Xtest)
accuracy=accuracy_score(Ytest,Ypred)
accuracy
